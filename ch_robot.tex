\documentclass[buriama8_dp.tex]{subfiles}
\begin{document}

\chapter{Robotic hardware and framework}

\section{ROS}
\label{sec:ros}

The arm (and the whole TRADR robot) run under the \emph{Robot Operating System} â€“ ROS \cite{ros_paper}. This framework allows us to build robot software in a very modular fashion by providing us with standardized units (\uvz{nodes}) and M-to-N communication links (\uvz{topics}). Each hardware component of the robot (e.g. a LIDAR or a motor driver) has its own driver node, and so does each functional software part (mapping, adaptive traversability etc.). In ROS, we can put these ready-made parts together easily and run them in a distributed fashion, as each node can run on a different computer and the system will automatically relay the information between the hosts. Th modularity also guides us to design small and manageable pieces of software that integrate well with the rest of the environment and provide the new functionality we want.

The ROS framework is only a common interface specification, with the actual implementation of a node completely independent on other nodes. Each node can be implemented in a different programming language, as long as they conform with the communication standards.

\subsection{ROS primitives}
\label{subsec:ros_prims}

Basic unit of information in ROS are \emph{messages}. A message is a tuple with named values of different types, possibly other messages. A Pose message, representing position and orientation of an object in space, contains a Position message (which in turn contains \m x, \m y, and \m z coordinates as floating point numbers) holding the information about the position of the object, and a Quaternion representing its orientation.

The basic communication links are \emph{topics}. Nodes write messages to topics, and other nodes can subscribe to the topics and consume messages from them. For example a sensor driver node publishes the sensor measurements for the rest of the system to use.

The second communication primitive provided by ROS core are \emph{services}. Services implement request-response behavior, when a client calls the service provided by a node and receives a response for its request. For example, a laser range meter driver could be implemented as a service, accepting requests for measurement and returning the outcome.

\subsection{Actions}
\label{subsec:ros_actions}

On top of these primitives, another interface type is implemented, the \emph{actions}. Actions are not a part of core ROS as topics and services, but have become a standard part of ROS interfaces.

Actions consist of a set of topics and and are similar to services. A client sends a request to the action server. The action server then sends feedback back to the client as it performs the requested action. When the server is done, the client is notified by a goal message.

A good example for an action server is one for driving the robot to a defined pose. The action server receives a Pose message and sets off. As the robot is under way, the server sends periodic updates on the current pose back to the client. When the final pose is reached, the server notifies the client that the work is done together with optional complimentary data, like the length of the path taken.


\section{Kinova JACO}
\label{sec:jaco}
We will be working with the Kinova JACO robotic arm. It is a 6 degrees of freedom lightweight robotic arm, designed by Kinova Robotics for use in assistive and collaborative applications. As it is meant to be mounted on mobile structures as wheelchairs, JACO's lightness makes it ideal for uses on mobile robots.

\subsection{Arm kinematics}
\label{subsec:arm_kinematics}

The arm has slightly unusual geometry in its wrist. The wrist is not spherical (the axes of its joints do not intersect in one point), but consists of three revolute joints that have angular offsets of \(60\degr\) (see Figure~\ref{fig:jaco_schema}). This limits the workspace where the arm has full 6DOF capabilities, as the rotation of the wrist is limited. Usage of some inverse kinematics solvers is also impossible due to the non-standard geometry.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{jaco_spec_drawing.png}
  \caption[JACO blueprint]{JACO arm technical specification. Note the wrist (last three joints) construction that limits the enf effector orientation. Taken from \cite{jaco_spec}}
  \label{fig:jaco_schema}
\end{figure}


\subsection{Arm workspace}
\TODO{Arm workspace}

\subsection{Kinova ROS driver}
\label{subsec:kinova_ros}

The manufacturer provides an open-source ROS library to operate the arm \cite{kinova_ros}. The driver runs a node that communicates with the arm via a USB interface and relays incoming commands from other components. The driver is an evolution of a former JACO ROS driver that supported only the JACO arm. Recently, Kinova replaced the JACO-specific driver with the new one, which supports also other Kinova arms.

The driver provides interfaces to moving the arm to joint space and Cartesian space targets, controlling fingers of the gripper and directly driving Cartesian velocity of the end effector and angular velocities of each joint \cite{kinova_ros_api}. It also provides two utility services for homing the arm and for stopping all movement immediately.

\subsection{Cartesian and joint space targets}
\label{subsec:api_cart_action}

Driving the arm to joint space and Cartesian space targets is possible via the respective action servers. The action servers accept Pose, resp. JointAngles message describing the desired target state. They report the current position back as the movement proceeds, and in the end return the actual pose the arm ended in. For the Cartesian pose target, no IK computation is performed by the driver itself, the target pose is only fed into the arm and the internal control algorithms take care of the rest. The movement also does not take any obstacle avoidance or collision prevention into account, except self-collisions that are checked.

\subsection{Cartesian and joint space velocity}
\label{subsec:api_cart_vel}

Controlling the arm movement via directly specifying velocities is implemented quite differently. To set Cartesian or joint angular velocities, the client publishes a message to a specified topic. The driver then forwards the message to the arm, where it is consumed from a queue by the arm's control algorithm. The control algorithm runs at 100\,Hz, and sets the velocity for the next iteration from the queue. Thus, once the client stops publishing to the topic, the movement stops immediately. The control is arguably implemented this way to minimize latency of stopping any movement. It also means, that to set the velocity for a longer time, the client needs to publish to the velocity control topic periodically at 100\,Hz. With lower frequency, the movement will be jagged, as some control loop iterations will set zero velocity. If the frequency were higher, the input queue of the arm would overflow, causing the arm to stall.

\subsection{Utility services}
\label{subsec:api_util}

Homing the arm is possible by calling a home service in the ROS driver. The home pose can be adjusted in the arm firmware by Kinova's arm controlling software.

The stop service stops all movements of the arm immediately. To resume operation, the arm must be started again by calling a start service. When restarted, all commands that came after stopping are dropped and need to be re-issued if they are to be carried out.

%%%
\section{MoveIt!}
\label{sec:moveit}

The ROS framework was primarily designed to operate whole mobile robots; it is not so well suited to control robotic manipulators. To help in this area, the MoveIt! package was designed to facilitate this task. It encompasses the full stack necessary to operate a robotic arm, from managing the state of the scene, through manipulation, motion planning, collision-checking, IK solving to outputting ommands that can be used directly to control a manipulator.

\subsection{MoveIt! architecture}
\label{subsec:mvt_arch}

MoveIt runs a large monolithic node called move group. The move group is responsible for all the operations of the arm. It consumes the state of the arm (joint angles) from the driver, as well as commands from the user issued via client libraries. The architecture is illustrated in Figure~\ref{fig:moveit_arch}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.9\textwidth]{moveit_arch}
  \caption[MoveIt! architecture]{Illustration of MoveIt! architecture. Taken from \cite{moveit_docs}}
  \label{fig:moveit_arch}
\end{figure}

The central node represents the move\_group, which listens to input from the robot hardware in the lower right, as point cloud sensors and introceptive sensors. It outputs commands to the manipulator to the controller with JointTrajectoryAction interface and is controlled by the inputs on the left. 

\subsection{User interface}
\label{subsec:moveit_ui}

The user interface, or client libraries, for MoveIt are prepared in C++ and python. The libraries contain objects and utility functions to use the functionality of the move group and communicate with the move group via its ROS topic and service interface. All the interfaces and functionalities are very poorly documented, and the best available resources are the automatically generated code documentation and the source code itself. The client libraries can be used directly to access the motion planning capabilities to reach some higher-level goals.


\subsection{Robot interface}
\label{subsec:moveit_ri}

MoveIt interfaces with the robot hardware by an action server implementing the JointTrajectoryAction. The server then drives the arm hardware. The JointTrajectoryAction is specified as a trajectory in space of joint angles and velocities, prepared by the motion planner with respect to both the arm kinematics (preventing collisions) and the arm dynamics (taking limits on joint velocities into account). The trajectory waypoints specify both the desired joint angles, as well as joint velocities necessary to reach the next waypoint. Each waypoint also specifies a point in time in which the arm should have reached it.

In case of the Kinova ROS driver, no such server is provided by the manufacturer. A pull request (code contributed by a developer) on GitHub containing this functionality exists, but is not a part of the release yet. We used an implementation of this server by MatÄ›j Balga\TODO{cite}, which we updated to work with the newest drivers from Kinova. The server is rather simplistic. It follows the joint velocities defined in the waypoints, forwarding them to the arm driver for as long as the waypoint specifies.

At the trajectory end, the current arm joint pose is compared to the desired final pose. If they are different, a simple P regulator is used to move the arm joints to within tolerance of the final positions. This behavior is very apparent after following a more complex trajectory, which includes many direction changes. It could prove dangerous for the arm when maneuvering in proximity of obstacles, as the arm strays off the collision-free trajectory. We assume this happens because the driver forwards the velocities to the arm directly, without taking accelerations into account. The arm firmware has acceleration limits built in, and when the limit is applied and the set velocity is truncated, the actual arm position diverges from the position expected by the driver.

The driver could possibly be improved by interpolating the velocities on a spline rather than linearly, smoothing out the velocity changes and thus not letting the arm firmware to interfere with the control.

\subsection{Inverse Kinematics solver -- TRAC-IK}
\label{subsec:tracik}

During our initial experiments with the arm, we encountered puzzling behaviors of the motion planners. The arm would sometimes move along a seemingly random, unnecessarily long path. At closer investigation, we concluded that the planning was actually optimal, but what was wrong was the Inverse Kinematic (\emph{IK}) solution for the target pose.

\TODO{Present forward and inverse kinematic theory? Maybe at least introduce the jacobian, as we use it later?}

Because of the slightly non-standard arm kinematics (see section \ref{subsec:arm_kinematics}), the default IK solver used by MoveIt (the KDL numerical solver) would sometimes produce a solution that indeed reaches the desired end effector pose, but that is very far in joint space from the current joint state, even when a very small end effector motion is required.

\begin{figure}[htp]
  \centering
  \begin{subfigure}[t]{0.49\textwidth}
    \includegraphics[width=\textwidth]{wrong_path.png}
    \caption{}
    \label{fig:wron_plan}
  \end{subfigure}
  \begin{subfigure}[t]{0.49\textwidth}
    \includegraphics[width=\textwidth]{wrong_joint_config.png}
    \caption{}
    \label{fig:wrong_joint}
  \end{subfigure}

  \caption{Prepare figures for wrong plan (a) and joint configuration (b)}
  \label{fig:wrong_planning}
\end{figure}

This is caused by the KDL implementation. KDL finds the IK solution by iterating

\TODO{Should the algorithm be here? Exclude it completely?}
\begin{algorithm}[ht]
\begin{algorithmic}
  \State \textbf{Input:} \(\vec p \gets\) desired target Cartesian pose
  \vspace{1em}

  \State \(\vec q \gets\) seed joint values
 
  \Do
    \State \(\vec p_c \gets\) computeFK(\(\vec q\))
    \State \(\mat J \gets\) computeJacobian(\(\vec q\))
    \State \(\vec e \gets \vec p_c - \vec p\)

    \State \(\vec q \gets \vec q + \mat J^+ \vec e \)
  \doWhile{\(|e|<\epsilon\)}

  \vspace{1em}
  \State \textbf{return} \(\vec q\)
\end{algorithmic}
\caption{KDL iterative IK solver}
\label{alg:kdlik}
\end{algorithm}

This approach is analogic to using the Newton method to minimize the Cartesian space error. The Jacobian matrix \(\mat J = (m_{i,j}) \in \R^{6 \times 6} \) is a matrix of partial derivatives where
\[
m_{i,j} = \frac{\pdiff{p_i}}{\pdiff q_j}
\label{eq:jacob}
\]
\marginpar{\TODO{revise \(i,j\)}}
and thus
\[
\mat J_{i,j}^{-1} = \frac{\pdiff{q_j}}{\pdiff p_i}.
\]
and by iteration in Algorithm~\ref{alg:kdlik} we descend the pose error by preforming its local linear approximation and taking a step that minimizes it. The pseudoinverse is used in KDL because \quot{it is more efficient to compute}{tracik}, while it is numerically more stable when computed via SVD decomposition.

The descent can get trapped in local minima when some of the joints limits are reached. This is solved by restarting the search from a random seed position. Then, the found position can be one very distant from the original position in joint space.

This issue is tackled by a new IK solver released recently, TRAC-IK \cite{tracik}. The solver implements another approach to solving the IK problem by formulating it as a Sequential Quadratic Programming problem, minimizing \(|e|^2\) with joint limits as constraints. The solver also allows the user to specify other constraints, like a wish to minimize joint-space distance between the seed (current arm joint values) and the result.

This setting allows us to eliminate the large joint space changes for minor movements, which was an issue with the JACO arm before. \TODO{It still happens, sometimes. Increase time?}

\subsection{Motion planning}
\label{subsec:moveit_motion_planning}

Planning the motion of the manipulator in an environment with obstacles is a very complex task, suffering heavily from the curse of dimensionality. We are planning in 6-dimensional control space, (joint velocities, accelerations or torques) from a given start pose to the target pose. Search-based planning algorithms fail because of the high dimension of the planning space, augmented by the need of fine space discretisation to keep the path smooth in the continuous real world. Specialized planners based on sampling the control space (Rapidly-exploring Random trees -- \emph{RRT} or Kinodynamic Interior-Exterior Cell Exploration -- \emph{KPIECE}) \TODO{cite} are used to make planning the movement faster.
RRT build a tree that covers the configuration space. It starts as a single node, the start state. In each step of the expansion, a node \m n is randomly chosen from the tree, with bias towards nodes that are in sparsely covered parts of the space (measured as number of nodes in a hypersphere with a given radius around each node). Then, a control input \m c is randomly sampled and a new node is created for the configuration reached from node \m n by applying the control input \m c for some time \(\Delta t\).

\TODO{KPIECE}

\TODO{post-processing}

\subsection{Moving the arm without planning}
\label{subsec:label}

The problem with motion planning is that it is a complex task in itself, and, even though it is readily available as a part of MoveIt, it is slow and sometimes yields bad plans, even after employing the optimizing IK solver TRAC-IK. In case of small movements, where a trivial linear path is often a good enough, if not optimal, solution, computing the whole huge motion plan is plain waste of resources and time.

The previous work \cite{vojta} used motion planning to carry out a simple downward motion, moving in 1\,cm steps. The same unneccesarily long paths have been reported.

It is not necessary to move the arm by following a motion plan. The algebraic model of a robotic arm, referred to as serial manipulator, allows us to convert movement from the cartesian space we (and the robot) percieve to the manipulator's joint space. As we mentioned above, when the manipulator is in joint configuration \(\vec q\) reaching end effector pose \(\vec p\) we can compute the Jacobian matrix of partial derivatives
\[
\mat J(\vec q) = (j_{i,j})= \frac{\pdiff{p_i}}{\pdiff q_j}.
\label{eq:jacob}
\]

With a slight abuse of notation, we can relate the former formula to the formula connecting joint and cantesian space
\[
\mat J(\vec q) \dot{\vec{q}} = \dot{\vec{p}}
\]
where we see that the Jacobian maps joint velocities \(\dot{\vec{q}}\) to cartesian pose velocities \(\dot{\vec{p}}\) (referred to in literature as \emph{twist}). Conversely, the Jacobian inverse (if it exists) maps cartesian speeds to joint speeds:
\[
\mat J^{-1}(\vec q) \dot{\vec{p}} = \dot{\vec{q}}
\]

The inverse does not need to exist, or can be highly unstable as the Jacobian can be badly numerically conditioned. The near singularity of the Jacobian means that any of the null space of joint speeds would cause end effector movement in the desired direction. Or that the end of the end effector cannot be moved in the desired direction without requiring infinite speeds of the joints. In the second case, we need to leave tehe singularity in another direction.

In the first case, the problem is underconstrainted and can be solved for least square norm solution, which means the slowest joint motion. With advantage we use the Moore-Penrose pseudoinverse expressed in SVD decomposition of \(\mat J = \mat U \mat S \mat V^T \):
\[
\mat J^\dagger(\vec q) = \mat V \mat S^{-1} \mat U^T
\]
This approach gives us opportunity to check the conditioning of the operation, inspecting the singular values and zeroing out those that are below the tolerance and that could cause the solution to fail. The pseudoinverse then gives us the joint velocities directly:
\[
 \dot{\vec{q}} = \mat J^\dagger(\vec q) \dot{\vec{p}}
\]

This whole process of obtaining joint velocities for a given twist is already implemented in MoveIt. The method is a part of RobotState, a class representing the joint configuration of the manipulator. Given the twist, the method computes the joint angulad velocities that result in the given twist in that joint configuration. The velocity is then applied only for a small amount of time in a control loop; in each iteration, the current state is obtained and the joint velocities corresponding to the twist are updated.

%%%
\section{Tactile sensing}

Previous work in the field of tactile exploration at FEE \cite{vojta} used effort readings from the arm joints to detect tool contact when exploring terrain. To prevent arm damage, the movement had to be very slow, making it painstaking to explore event very little of the environment.

To improve exploration efficiency, we used a 3D force sensor to detect whether our tool is in contact with the environment. This allows us to move the arm much faster with confidence that we will be able to stop the arm with latency low enough to guarantee the arm nor the force sensor would be harmed.

\subsection{Optoforce sensor}
\label{subsec:opto}

The force sensor used is an Optoforce OMD-20-SE-40N sensor. Optoforce sensors represent a novel approach to 3D force sensor construction, as their working principle enables them to be made very rugged, resilient.


\begin{figure}[ht]
  \begin{subfigure}[t]{0.4\textwidth}
    \includegraphics[width=\textwidth]{OMD-sketch-with-axises}
    \caption{}
    \label{fig:omd_geom}
  \end{subfigure}
  \begin{subfigure}[t]{0.4\textwidth}
    \includegraphics[width=\textwidth]{OMD-xsec}
    \caption{}
    \label{fig:omd_xsec}
  \end{subfigure}

  \caption[Optoforce sensor]{The optoforce sensor reference frame (a) and cross-section (b). Taken from \cite{opto_whitep}}
  \label{fig:decomps}
\end{figure}\


The Optoforce sensor, seen in cross-section in Figure~\ref{fig:omd_xsec}, consists of an aliminium base plate, made in different designs, and a hollow silicone hemispherical dome. The interior of the dome is coated with a reflective layer. A light emitter, IR LED, is positioned on the base plate in the center of the dome. Four light-sensitive diodes are placed around it.

When the sensor is operational, the LED emits light which bounces around the dome and provides known, constant illumination on the photodiodes. When force is applied to the dome, it deforms, and the deformation causes the illumination of the diodes to shift. From this shift, it is possible to determine the direction in which the force has been applied. According to the manufacturer, deformations in range of hundreds of nanometers can be measured \cite{opto_whitep}.

The sensor has its own DAQ (\emph{Data AcQuisition}) module, which communicates with a computer via a serial link emulated over USB. The manufacturer provides a C++ library that exposes the sensor functionality in an API. It however depends on the problematic Qt framework. Shadow Robot Company \cite{opto_driver}  implemented a ROS node that connects to the sensor serial interface, configures sensor parameters like measurement and filter frequency, reads the data output by the sensor and publishes them on a ROS topic to be processed by other components. The readings published are in Newtons, as the driver is provided with a \uvz{sensitivity report}, a calibration result provided by the manufacturer that relates the internal units used bu the sensor to actual physical forces. The driver software was released under GPLv2. We simplified the driver and slightly adjusted it to work better in our setup.


\section{Contributions to the hardware and framework}
\label{sec:hw_contrib}

\subsection{Arm simulator}
\label{subsec:arm_sim}

To simplify development, we implemented a fake arm driver mimicking the Kinova ROS driver. The fake driver is meant to be used with MoveIt! as a drop-in replacement of the original driver, and hence it only implements FollowJointTrajectory action. It receives a joint speed trajectory, and replays it, publishing fake arm configuration to the respective topic where the rest of the system expects robot joint readings. Then, the rest of the system cannot distinguish the fake arm and the real robot.

The fake driver can be configured to execute the joint trajectories faster, to save time the user spends watching the simulated arm move. The fake driver does not simulate arm dynamics in any way, it only tries to follow the trajectory in the same way as the real driver does. In the end, instead of being driven by a regulator to the real target angles, we set the joint angles directly.

This simulator allows us to test the system without the need of using, driving and taking care of a expensive physical arm.


\subsection{Sensing tool and measurement processing}
\label{subsec:sense_tool}

The Optoforce sensor is relatively small. Mounting it on the JACO arm and using it to sense direct contact with an obstacle would mean the arm would get uncomfortably close to it. We devised a way to extend the sensor so that force readings are taken not at the sensor dome, but at a stick. This increases the arm range and makes it possible to keep the arm safely away from unknown obstacles.

The sensor is mounted in a frame together with a stick. The stick ends at the sensor with a specially designed cap that transfers forces from the stick to the dome of the sensor itself. The other end of the stick is blunted not to be dangerous to its surroundings.

\begin{figure}[htp]
  \centering

  \begin{subfigure}[t]{0.44\textwidth}
   \includegraphics[width=\textwidth]{otpo_frame.pdf}
   \caption{\label{fig:opto_frame}}
  \end{subfigure}
  %
  \begin{subfigure}[t]{0.44\textwidth}
   \includegraphics[width=\textwidth]{otpo_frame_forces.pdf}
   \caption{\label{fig:frame_forces}}
  \end{subfigure}

 \caption[Sensing tool]{The sensing tool assembly in cross-section (a) and forces in the instrument (b)}
 \label{fig:opto_frame_fig}
\end{figure}


\begin{figure}[htp]
  \centering
  \includegraphics[width=7cm]{sensing_toool_photo.png}
  \caption{The sensing tool}
  \label{fig:tool_photo} 
\end{figure}

The stick acts as a lever with the pivot point being the assembly frame. When a lateral force is applied to the stick, the sensor records force in opposite direction. Axial force is applied directly to the sensor. The principle is illustrated in Figure~\ref{fig:frame_forces}.

The sensor dome is in contact with a cap attached to the stick. The cap is pressed against the dome with a preloaded force, to ensure accurate measurement of even very small forces applied to the stick. The deformation of the dome is limited by a pair of nuts that limit the travel of the stick.

The whole assembly is mounted to a lump of plastic ergonomically designed for the JACO 3-finger gripper, so that the sensor can be attached to the hand without any hassle and operatively, and could, in theory, be mounted somewhere on the robot and taken by the arm automatically only when necessary.

\begin{figure}[ht]
  \centering
  \includegraphics[width=7cm]{lump.png}
  \caption{The ergonomical grip handle we designed to facilitate mounting hardware onto the arm. The square base can be used to mount any object to the handle in the future. The 3-finger gripper on the arm can hold it firmly enough to withstand considerable force}
  \label{fig:label}
\end{figure}


\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "buriama8_dp"
%%% End:
